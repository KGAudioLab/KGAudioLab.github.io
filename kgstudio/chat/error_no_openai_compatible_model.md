### OpenAI Compatible Model Required

You selected OpenAI Compatible as your LLM Provider, but no Model is configured.

How to fix:
- Go to **Settings ⚙️ → General → OpenAI Compatible Server**
- Enter a **Model** (e.g., `qwen/qwen3-235b-a22b:free`, etc.)

After updating your settings, try your request again.